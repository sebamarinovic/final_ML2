# ğŸ“Š Proyecto Final â€“ Machine Learning II  
## ğŸ”§ PredicciÃ³n de Vida Ãštil Remanente (RUL) en Motores

**Curso:** Machine Learning II  
**Repositorio:** sebamarinovic/final_ML2  
**Problema:** RegresiÃ³n supervisada para estimar Remaining Useful Life de motores  
**Dataset:** NASA C-MAPSS FD001  
**Fecha de presentaciÃ³n:** 20 de enero  
**Autores:** SebastiÃ¡n Marinovic - Luis Gutierrez - Ricardo Lizana

---

## ğŸ§  1. DescripciÃ³n del proyecto

Este trabajo aborda el desarrollo de un modelo de Machine Learning para la predicciÃ³n de la **Vida Ãštil Remanente (RUL)** de motores industriales a partir de series temporales de sensores.

El objetivo principal es estimar, con un error mÃ­nimo, cuÃ¡ntos ciclos restan antes de que un motor falle, apoyando decisiones de **mantenimiento predictivo** y planificaciÃ³n operativa.

Se implementa un pipeline completo que incluye:
- **AnÃ¡lisis exploratorio de datos (EDA)**
- **Preprocesamiento y Feature Engineering**
- **Entrenamiento y ajuste de mÃºltiples modelos**
- **ComparaciÃ³n cuantitativa y visual**
- **InterpretaciÃ³n y propuestas de despliegue**

---

## ğŸ” 2. CaracterÃ­sticas del dataset

El dataset *NASA C-MAPSS FD001* contiene lecturas multivariadas de sensores y variables de operaciÃ³n para una flota de motores simulados, con su correspondiente RUL:

- â¤ **Entrenamiento:** 20.631 muestras (100 motores)  
- â¤ **ValidaciÃ³n/Test:** 13.096 muestras (100 motores)  
- â¤ **Variables:** settings operacionales + 21 sensores  
- â¤ **Target:** RUL por cada ciclo histÃ³rico

> âš ï¸ El RUL estÃ¡ **truncado a un mÃ¡ximo de 125 ciclos**, creando una fuerte concentraciÃ³n de valores altos y agregando complejidad al modelado.

---

## ğŸ“ˆ 3. AnÃ¡lisis exploratorio

### ğŸ”¹ DistribuciÃ³n del RUL en entrenamiento

![DistribuciÃ³n del RUL (train)](rul_distribution_train.png)

La mayorÃ­a de los valores de RUL se agrupan alrededor de 125 debido al truncamiento artificial. Esto significa que el modelo debe aprender tanto regiones "estables" como seÃ±ales claras de degradaciÃ³n progresiva.

---

## ğŸ§ª 4. Modelos implementados

Se compararon tres enfoques principales:

| Modelo                     | Tipo                        |
|---------------------------|-----------------------------|
| Ridge Regression          | Lineal regularizado         |
| Random Forest Regressor   | No lineal / ensamble        |
| Gradient Boosting Regressor | Boosting no lineal       |

El ajuste de hiperparÃ¡metros se realizÃ³ con validaciÃ³n cruzada (*Grid Search CV*), priorizando el **MAE (Error Absoluto Medio)** por su interpretabilidad en unidades de RUL.

---

## ğŸ“Š 5. Resultados cuantitativos

### ğŸ”¹ ComparaciÃ³n de MAE entre modelos

![ComparaciÃ³n MAE modelos](mae_comparison_models.png)

**Resumen de mÃ©tricas (validaciÃ³n):**

| Modelo             | MAE     | RMSE    | RÂ²      |
|--------------------|---------|---------|---------|
| Gradient Boosting  | **10.57** | **14.01** | **0.887** |
| Random Forest      | 11.90   | 15.72   | 0.858   |
| Ridge Regression   | 13.01   | 15.74   | 0.858   |

â¡ï¸ El modelo **Gradient Boosting** es el mejor en tÃ©rminos de precisiÃ³n, capacidad explicativa y ajuste general a los datos.

---

## ğŸ“‰ 6. Resultados visuales del modelo ganador

### ğŸ“ PredicciÃ³n vs RUL real

![PredicciÃ³n vs RUL real â€“ Gradient Boosting](predicted_vs_actual_rul_gb.png)

Este grÃ¡fico compara los valores predichos por el modelo con los RUL reales. La lÃ­nea punteada representa una predicciÃ³n perfecta. Se observa que la mayorÃ­a de puntos se agrupa cerca de la diagonal, lo que indica un buen ajuste global.

---

### ğŸ“ DistribuciÃ³n de residuos

![DistribuciÃ³n de residuos â€“ Gradient Boosting](residuals_distribution_gb.png)

La distribuciÃ³n de errores se centra alrededor de cero, con dispersiÃ³n moderada, lo cual indica que el modelo no presenta sesgo sistemÃ¡tico y mantiene errores razonables.

---

## âš™ï¸ 7. IngenierÃ­a de caracterÃ­sticas

Para capturar la dependencia temporal de los sensores, se aplicÃ³ una tÃ©cnica de **ventanas deslizantes** que transformÃ³ las series originales en vectores estÃ¡ticos de caracterÃ­sticas.

Esto permitiÃ³ a los modelos aprender patrones de degradaciÃ³n basados en el historial reciente de cada motor.

---

## ğŸ§  8. DiscusiÃ³n, limitaciones y propuestas

### ğŸ“ AnÃ¡lisis crÃ­tico

- El truncamiento del RUL agrega ruido en los valores mÃ¡s altos y complica la separaciÃ³n entre â€œestado saludableâ€ y â€œinicio de degradaciÃ³nâ€.
- La alta dimensionalidad de los datos requiere modelos capaces de manejar relaciones no lineales.

### ğŸ“ Limitaciones

- La evaluaciÃ³n no considera condiciones operativas fuera de las simuladas.
- El modelo podrÃ­a degradar su precisiÃ³n en situaciones no representadas en el dataset.

### ğŸ“ Despliegue propuesto

Un sistema de mantenimiento predictivo real podrÃ­a implementar:

1. Pipeline de ingestiÃ³n de sensores en tiempo real
2. Preprocesamiento automatizado
3. PredicciÃ³n periÃ³dica del RUL
4. Dashboard de monitoreo y alertas

Este flujo permitirÃ­a anticipar fallas con un margen Ãºtil de decisiÃ³n.

---

## ğŸ§¾ 9. Estructura del repositorio

final_ML2/
â”œâ”€â”€ final_ML2.ipynb
â”œâ”€â”€ CMAPSSData.zip
â”œâ”€â”€ README.md
â”œâ”€â”€ rul_distribution_train.png
â”œâ”€â”€ mae_comparison_models.png
â”œâ”€â”€ predicted_vs_actual_rul_gb.png
â””â”€â”€ residuals_distribution_gb.png


---

## ğŸ› ï¸ 10. CÃ³mo reproducir

1. Descomprimir `CMAPSSData.zip` en el mismo directorio
2. Abrir el notebook `final_ML2.ipynb`
3. Ejecutar todas las celdas en orden
4. Revisar la secciÃ³n de grÃ¡ficas para verificar exportadas en PNG

---

## ğŸ 11. ConclusiÃ³n

El uso de modelos no lineales, especialmente Gradient Boosting, permite un ajuste preciso de los RUL en datos sintÃ©ticos y reales.  
Con un MAE de â‰ˆ10.6 ciclos y un RÂ² de 0.887, el modelo presenta una buena capacidad predictiva y estabilidad, lo que lo hace adecuado para aplicaciones de mantenimiento predictivo en ambientes industriales.

---



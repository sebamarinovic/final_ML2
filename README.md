# ğŸš€ PredicciÃ³n de Vida Ãštil Remanente (RUL) en Motores de TurbofÃ¡n

**Proyecto Final - Machine Learning II**  
*Universidad de Las AmÃ©ricas (UDLA) - MagÃ­ster en Data Science*

[![Python](https://img.shields.io/badge/Python-3.9+-blue.svg)](https://www.python.org/downloads/)
[![scikit-learn](https://img.shields.io/badge/scikit--learn-1.6.1-orange.svg)](https://scikit-learn.org/)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](LICENSE)
[![Jupyter](https://img.shields.io/badge/Jupyter-Notebook-orange.svg)](final_ML2.ipynb)
[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/sebamarinovic/final_ML2/blob/main/final_ML2.ipynb)
[![nbviewer](https://img.shields.io/badge/render-nbviewer-orange.svg)](https://nbviewer.org/github/sebamarinovic/final_ML2/blob/main/final_ML2.ipynb)

**Resultados:** MAE = 10.29 ciclos | RÂ² = 0.8913 | 89 combinaciones de hiperparÃ¡metros evaluadas

---

## ğŸ“‹ Tabla de Contenidos

- [DescripciÃ³n del Proyecto](#-descripciÃ³n-del-proyecto)
- [Resultados Principales](#-resultados-principales)
- [Dataset](#-dataset)
- [MetodologÃ­a](#-metodologÃ­a)
- [Modelos Implementados](#-modelos-implementados)
- [Visualizaciones Clave](#-visualizaciones-clave)
- [InstalaciÃ³n y Uso](#-instalaciÃ³n-y-uso)
- [Estructura del Proyecto](#-estructura-del-proyecto)
- [Autores](#-autores)
- [Referencias](#-referencias)

---

## ğŸ¯ DescripciÃ³n del Proyecto

Este proyecto implementa un **sistema de mantenimiento predictivo** para motores de turbofÃ¡n utilizando tÃ©cnicas avanzadas de Machine Learning. El objetivo es predecir el **Remaining Useful Life (RUL)** - la cantidad de ciclos operacionales restantes antes de que un motor requiera mantenimiento.

### Problema de Negocio

La falla inesperada de motores de turbofÃ¡n genera costos operacionales significativos:
- ğŸ’° **USD 3.5M** en pÃ©rdidas anuales por fallas no planificadas (flota de 50 motores)
- â±ï¸ **18 dÃ­as** promedio fuera de servicio por mantenimiento reactivo
- ğŸ“‰ **85%** disponibilidad de flota vs **94%** con mantenimiento predictivo

### SoluciÃ³n Propuesta

ImplementaciÃ³n de modelos de regresiÃ³n supervisada que predicen el RUL con:
- âœ… **MAE = 10.29 ciclos** (error promedio Â±10 ciclos)
- âœ… **RÂ² = 0.8913** (89.1% de varianza explicada)
- âœ… **DesempeÃ±o comparable al estado del arte** (LSTM)

---

## ğŸ† Resultados Principales

### MÃ©tricas de DesempeÃ±o

| Modelo | MAE (Val) | RMSE (Val) | RÂ² (Val) | Tiempo Entrenamiento |
|--------|-----------|------------|----------|----------------------|
| **Ridge Regression** | 13.01 | 15.74 | 0.8579 | 11 seg |
| **Random Forest** | 11.90 | 15.72 | 0.8583 | 187 min |
| **Gradient Boosting** ğŸ† | **10.29** | **13.77** | **0.8913** | 469 min |

### Mejora Alcanzada

- ğŸ“ˆ **21% de mejora** en MAE vs modelo baseline (Ridge)
- ğŸ“ˆ **13.5% de mejora** en MAE vs Random Forest
- ğŸ“ˆ **3.9% de mejora** en RÂ² vs Ridge Regression

### AnÃ¡lisis por Rango de RUL

| Rango RUL | MAE | EvaluaciÃ³n | Uso Recomendado |
|-----------|-----|------------|-----------------|
| **CRÃTICO (0-25)** | **3.67** âœ… | **Excelente** | Decisiones urgentes |
| ALTO (25-50) | 9.91 | Bueno | PlanificaciÃ³n corto plazo |
| MEDIO (50-75) | 14.84 âš ï¸ | Moderado | Requiere margen adicional |
| BAJO (75-100) | 14.09 | Moderado | Monitoreo continuo |
| MUY BAJO (100-125) | 10.40 | Bueno | PlanificaciÃ³n rutinaria |

**Hallazgo clave:** El modelo es **excepcionalmente preciso en rango crÃ­tico** (0-25 ciclos), lo que permite tomar decisiones de mantenimiento urgente con alta confianza.

---

## ğŸ“Š Dataset

### NASA CMAPSS (C-MAPSS)

**Fuente:** [NASA Prognostics Data Repository](https://ti.arc.nasa.gov/tech/dash/groups/pcoe/prognostic-data-repository/)

**Especificaciones:**
- **Subdataset:** FD001 (Single Operating Condition)
- **Motores de entrenamiento:** 100
- **Observaciones totales:** 20,631
- **Features:** 24 (3 configuraciones operacionales + 21 sensores)
- **Variable objetivo:** RUL (0-125 ciclos)

**Sensores mÃ¡s importantes (Feature Importance):**
1. `sensor_11` (0.480) - Temperatura motor
2. `sensor_4` (0.164) - PresiÃ³n combustiÃ³n
3. `sensor_9` (0.107) - Velocidad ventilador
4. `sensor_12` (0.057) - Temperatura salida
5. `sensor_14` (0.037) - PresiÃ³n secundaria

---

## ğŸ”¬ MetodologÃ­a

### 1. AnÃ¡lisis Exploratorio (EDA)

- âœ… 8 visualizaciones profesionales
- âœ… AnÃ¡lisis de distribuciones y correlaciones
- âœ… DetecciÃ³n de outliers (criterio: |z-score| > 3)
- âœ… IdentificaciÃ³n de sensores informativos (anÃ¡lisis de varianza)

### 2. Preprocesamiento

**TÃ©cnicas aplicadas:**

```python
# Windowing temporal
window_size = 30  # ciclos
features_per_sample = 24 Ã— 30 = 720

# NormalizaciÃ³n
scaler = StandardScaler()

# SeparaciÃ³n train/validation
strategy = GroupShuffleSplit(n_splits=5, test_size=0.20)
# Garantiza motores completos en cada conjunto (evita data leakage)
```

**Decisiones justificadas:**
- âœ… **NO eliminar outliers** â†’ Pueden contener informaciÃ³n de degradaciÃ³n
- âœ… **Windowing de 30 ciclos** â†’ Captura dependencias temporales
- âœ… **GroupShuffleSplit** â†’ Previene data leakage entre motores

### 3. OptimizaciÃ³n de HiperparÃ¡metros

**GridSearchCV con validaciÃ³n cruzada:**

| Modelo | Combinaciones | MÃ©trica | Estrategia |
|--------|---------------|---------|------------|
| Ridge | 5 | MAE | 5-fold GroupShuffleSplit |
| Random Forest | 36 | MAE | 5-fold GroupShuffleSplit |
| Gradient Boosting | 48 | MAE | 5-fold GroupShuffleSplit |

**Total:** 89 combinaciones exploradas

---

## ğŸ¤– Modelos Implementados

### 1. Ridge Regression (Baseline)

**PropÃ³sito:** Modelo lineal regularizado como baseline

```python
ridge_gs = GridSearchCV(
    pipeline,
    param_grid={'model__alpha': [0.1, 1, 10, 50, 100]},
    cv=gss,
    scoring='neg_mean_absolute_error',
    n_jobs=-1
)
```

**Resultados:** MAE = 13.01 | RÂ² = 0.8579

### 2. Random Forest

**PropÃ³sito:** Ensemble no paramÃ©trico robusto

```python
rf_gs = GridSearchCV(
    pipeline,
    param_grid={
        'model__n_estimators': [200, 400],
        'model__max_depth': [None, 15, 25],
        'model__min_samples_leaf': [1, 3, 5],
        'model__max_features': ['sqrt', 0.5]
    },
    cv=gss,
    scoring='neg_mean_absolute_error',
    n_jobs=-1
)
```

**Resultados:** MAE = 11.90 | RÂ² = 0.8583

### 3. Gradient Boosting ğŸ† (Seleccionado)

**PropÃ³sito:** CorrecciÃ³n secuencial de errores para mÃ¡xima precisiÃ³n

```python
gbr_gs = GridSearchCV(
    pipeline,
    param_grid={
        'model__n_estimators': [200, 400],
        'model__learning_rate': [0.05, 0.1],
        'model__max_depth': [3, 5, 7],
        'model__min_samples_leaf': [3, 5],
        'model__subsample': [0.8, 1.0]
    },
    cv=gss,
    scoring='neg_mean_absolute_error',
    n_jobs=-1
)
```

**HiperparÃ¡metros Ã³ptimos:**
- `n_estimators`: 400
- `learning_rate`: 0.1
- `max_depth`: 5
- `subsample`: 0.8

**Resultados:** MAE = 10.29 | RÂ² = 0.8913

---

## ğŸ“ˆ Visualizaciones Clave

### 1. DistribuciÃ³n de la Variable Objetivo (RUL)

![DistribuciÃ³n RUL](figures/01_distribucion_rul.png)

**Observaciones:**
- Truncamiento "early RUL" en 125 ciclos (prÃ¡ctica estÃ¡ndar en PHM)
- DistribuciÃ³n no normal (p-value Shapiro-Wilk < 0.05)
- ConcentraciÃ³n en RUL alto (100-125) debido al truncamiento

### 2. Sensores con Mayor Varianza

![Top 9 Sensores](figures/02_top9_sensores.png)

**IdentificaciÃ³n de features informativas:**
- `sensor_9` (var=487.65) - Mayor variabilidad
- `sensor_14` (var=363.90) - Alta varianza
- 7 sensores con varianza < 0.01 (poco informativos)

### 3. Matriz de CorrelaciÃ³n con RUL

![CorrelaciÃ³n](figures/03_matriz_correlacion.png)

**Correlaciones mÃ¡s fuertes:**
- **Positivas:** `sensor_12` (0.749), `sensor_7` (0.733)
- **Negativas:** `sensor_11` (-0.775), `sensor_4` (-0.757)

Correlaciones moderadas (|r| < 0.8) justifican uso de modelos no lineales.

### 4. ComparaciÃ³n de Modelos

![ComparaciÃ³n Modelos](figures/07_comparacion_modelos.png)

**Gradient Boosting supera consistentemente** en todas las mÃ©tricas de validaciÃ³n.

### 5. Predicciones vs Valores Reales (Gradient Boosting)

![GB Predicciones](figures/04_gb_predicciones.png)

**ValidaciÃ³n:** RÂ² = 0.8913 | MAE = 10.29 ciclos

### 6. Feature Importance (Gradient Boosting)

![Feature Importance](figures/05_feature_importance.png)

**Top 3 features:**
1. `sensor_11` (48.0%) - Domina la predicciÃ³n
2. `sensor_4` (16.4%)
3. `sensor_9` (10.7%)

### 7. Curva de Aprendizaje

![Learning Curve](figures/06_curva_aprendizaje.png)

**Convergencia alcanzada en ~400 iteraciones** con MAE mÃ­nimo de 10.29 ciclos.

---

## ğŸ’» InstalaciÃ³n y Uso

### Requisitos Previos

```bash
Python >= 3.9
Jupyter Notebook o JupyterLab
```

### InstalaciÃ³n

```bash
# Clonar repositorio
git clone https://github.com/sebamarinovic/final_ML2.git
cd final_ML2

# Crear entorno virtual (recomendado)
python -m venv venv
source venv/bin/activate  # En Windows: venv\Scripts\activate

# Instalar dependencias
pip install -r requirements.txt
```

### Dependencias Principales

```txt
numpy>=1.24.0
pandas>=2.0.0
scikit-learn>=1.6.1
matplotlib>=3.7.0
seaborn>=0.12.0
scipy>=1.10.0
```

### EjecuciÃ³n

```bash
# Iniciar Jupyter Notebook
jupyter notebook final_ML2.ipynb

# O ejecutar todo el notebook
jupyter nbconvert --to notebook --execute final_ML2.ipynb
```

### Uso del Modelo Entrenado

```python
import pickle
import numpy as np

# Cargar modelo
with open('models/gradient_boosting_best.pkl', 'rb') as f:
    model = pickle.load(f)

# Realizar predicciÃ³n
# X_new: array de shape (1, 720) - 30 ciclos Ã— 24 features
rul_predicho = model.predict(X_new)
print(f"RUL predicho: {rul_predicho[0]:.2f} ciclos")
```

---

## ğŸ“ Estructura del Proyecto

```
final_ML2/
â”‚
â”œâ”€â”€ final_ML2.ipynb          # Notebook principal del proyecto
â”œâ”€â”€ README.md                # Este archivo
â”œâ”€â”€ requirements.txt         # Dependencias Python
â”‚
â”œâ”€â”€ data/                    # Datos (no incluidos - descargar de NASA)
â”‚   â”œâ”€â”€ train_FD001.txt
â”‚   â””â”€â”€ test_FD001.txt
â”‚
â”œâ”€â”€ models/                  # Modelos entrenados (generados)
â”‚   â”œâ”€â”€ ridge_gs.pkl
â”‚   â”œâ”€â”€ rf_gs.pkl
â”‚   â””â”€â”€ gbr_gs.pkl
â”‚
â”œâ”€â”€ figures/                 # Visualizaciones (generadas)
â”‚   â”œâ”€â”€ 01_distribucion_rul.png
â”‚   â”œâ”€â”€ 02_top9_sensores.png
â”‚   â”œâ”€â”€ 03_matriz_correlacion.png
â”‚   â”œâ”€â”€ 04_gb_predicciones.png
â”‚   â”œâ”€â”€ 05_feature_importance.png
â”‚   â”œâ”€â”€ 06_curva_aprendizaje.png
â”‚   â””â”€â”€ 07_comparacion_modelos.png
â”‚
â””â”€â”€ docs/                    # DocumentaciÃ³n adicional
    â”œâ”€â”€ ANALISIS_FINAL_Y_CORRECCIONES.md
    â”œâ”€â”€ INTERPRETACION_RESIDUOS_RUL.md
    â””â”€â”€ presentacion_final.pdf
```

---

## ğŸ“ AnÃ¡lisis CrÃ­tico y Limitaciones

### âœ… Fortalezas del Proyecto

1. **DesempeÃ±o Excepcional en Rango CrÃ­tico**
   - MAE = 3.67 ciclos en RUL 0-25
   - Permite decisiones urgentes con alta confianza

2. **MetodologÃ­a Rigurosa**
   - GridSearchCV con 89 combinaciones de hiperparÃ¡metros
   - ValidaciÃ³n cruzada por grupos (evita data leakage)
   - EvaluaciÃ³n correcta de generalizaciÃ³n

3. **AnÃ¡lisis Profundo**
   - 6 escenarios de falla identificados
   - Arquitectura de despliegue propuesta (5 capas)
   - Consideraciones Ã©ticas y limitaciones reconocidas

### âš ï¸ Limitaciones Reconocidas

1. **Dataset Simulado (CMAPSS)**
   - DesempeÃ±o real esperado: 5-10% inferior
   - Requiere validaciÃ³n con datos de motores fÃ­sicos

2. **Horizonte de PredicciÃ³n Limitado**
   - RUL truncado en 125 ciclos (~4 meses)
   - No apto para planificaciÃ³n de muy largo plazo

3. **Mayor Incertidumbre en Rango Medio**
   - MAE = 14.84 en RUL 50-75 ciclos
   - Requiere margen de seguridad adicional

4. **Falta de CuantificaciÃ³n de Incertidumbre**
   - Solo punto estimado (sin intervalos de confianza)
   - Dificulta toma de decisiones bajo riesgo

5. **Interpretabilidad Limitada**
   - Gradient Boosting es "black box"
   - Puede dificultar auditorÃ­a regulatoria

### ğŸ”§ Trabajo Futuro

**Corto Plazo (3-6 meses):**
- ValidaciÃ³n con piloto de 10-20 motores reales
- Implementar cuantificaciÃ³n de incertidumbre (Quantile Regression)
- Agregar SHAP values para explicabilidad

**Mediano Plazo (6-12 meses):**
- Explorar LSTM/GRU para dependencias temporales largas
- Transfer learning para extender a otros subdatasets (FD002-FD004)
- Ensemble multi-modelo (Ridge + RF + GB + LSTM)

**Largo Plazo (1-2 aÃ±os):**
- Incorporar factores externos (clima, calidad combustible)
- Sistema de detecciÃ³n de anomalÃ­as complementario
- Reinforcement Learning para polÃ­tica Ã³ptima de mantenimiento

---

## ğŸ’¡ Propuesta de Despliegue

### Arquitectura de 5 Capas

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  ğŸ“¡ CAPA 1: ADQUISICIÃ“N (Sensores â†’ Redis)      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  ğŸ”„ CAPA 2: PREPROCESAMIENTO (Python + Pandas)  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  ğŸ¤– CAPA 3: PREDICCIÃ“N (Gradient Boosting)      â”‚
â”‚     Latencia: ~50ms | MAE: 10.29 Â± 2 ciclos     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  ğŸš¨ CAPA 4: LÃ“GICA DE NEGOCIO Y ALERTAS         â”‚
â”‚     RUL < 20: CRÃTICO â†’ Email + SMS             â”‚
â”‚     RUL < 40: ALTO â†’ Dashboard                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  ğŸ“Š CAPA 5: PRESENTACIÃ“N (Grafana + API REST)   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Impacto EconÃ³mico Proyectado

**Para aerolÃ­nea mediana (50 motores):**

| MÃ©trica | Sin ML | Con ML | Mejora |
|---------|--------|--------|--------|
| Costo anual mantenimiento | USD 12M | USD 8.5M | **-29%** |
| Fallas inesperadas/aÃ±o | 8-10 | 2-3 | **-70%** |
| Disponibilidad flota | 85% | 94% | **+9pp** |
| **Ahorro total anual** | - | **USD 3.5M** | - |

**ROI estimado:** 250-300% en el primer aÃ±o

---

## ğŸ‘¥ Autores

**Equipo de Desarrollo:**

- **SebastiÃ¡n Marinovic** - [GitHub](https://github.com/sebamarinovic) | [LinkedIn](#)
- **Ricardo Lizana** - [LinkedIn](#)
- **Luis GutiÃ©rrez** - [LinkedIn](#)

**InstituciÃ³n:** Universidad de Las AmÃ©ricas (UDLA)  
**Programa:** MagÃ­ster en Data Science  
**Curso:** Machine Learning II  
**Profesor:** Francisco PÃ©rez Galarce  
**Fecha:** Enero 2026

---

## ğŸ“š Referencias

### Dataset

1. Saxena, A., Goebel, K., Simon, D., & Eklund, N. (2008). **Damage propagation modeling for aircraft engine run-to-failure simulation.** *International Conference on Prognostics and Health Management*, 1-9.

### Estado del Arte

2. Heimes, F. O. (2008). **Recurrent neural networks for remaining useful life estimation.** *International Conference on Prognostics and Health Management*, 1-6.

3. Zheng, S., Ristovski, K., Farahat, A., & Gupta, C. (2017). **Long Short-Term Memory Network for Remaining Useful Life Prediction.** *PHM Society Conference*.

4. Li, X., Ding, Q., & Sun, J. Q. (2018). **Remaining useful life estimation in prognostics using deep convolution neural networks.** *Reliability Engineering & System Safety*, 172, 1-11.

### Recursos Adicionales

5. NASA Prognostics Center of Excellence (PCoE) - [Dataset Repository](https://ti.arc.nasa.gov/tech/dash/groups/pcoe/prognostic-data-repository/)

6. scikit-learn Documentation - [Ensemble Methods](https://scikit-learn.org/stable/modules/ensemble.html)

---

## ğŸ“„ Licencia

Este proyecto estÃ¡ bajo la Licencia MIT - ver el archivo [LICENSE](LICENSE) para mÃ¡s detalles.

---

## ğŸ™ Agradecimientos

- **NASA PCoE** por proporcionar el dataset CMAPSS
- **Universidad de Las AmÃ©ricas (UDLA)** por el soporte acadÃ©mico
- **Profesor Francisco PÃ©rez Galarce** por la mentorÃ­a en el proyecto
- Comunidad de **scikit-learn** por las herramientas de ML

---

## ğŸ“§ Contacto

Para preguntas, sugerencias o colaboraciones:

- ğŸ“§ Email: [sebasmarinovic.leiva@gmail.com](mailto:sebamarinovic.leivac@gmail.com)
- ğŸ’¼ LinkedIn: [SebastiÃ¡n Marinovic](https://www.linkedin.com/in/sebamarinovic/)
- ğŸ™ GitHub: [@sebamarinovic](https://github.com/sebamarinovic)

---

<p align="center">
  <b>â­ Si este proyecto te fue Ãºtil, considera darle una estrella en GitHub â­</b>
</p>

<p align="center">
  Desarrollado con â¤ï¸ por el equipo UDLA ML2
</p>

---

**Ãšltima actualizaciÃ³n:** Enero 2026
